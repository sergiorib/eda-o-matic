{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45eb194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy \n",
    "from typing import List, Dict, Any, Optional\n",
    "from charset_normalizer import from_path \n",
    "\n",
    "MAIN_PATH = Path().resolve().parent\n",
    "sys.path.append(str(MAIN_PATH))\n",
    "\n",
    "from src.utilities import load_config, load_validations, load_fields, load_data, init_log, format_file_size\n",
    "\n",
    "import src.analisys \n",
    "from src.analisys import field_apply_list, check_null_empty, check_values_list, check_regex_format, check_zero_values, check_negative_values, check_valid_range\n",
    "\n",
    "from src.utilities.logger import log_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cc5f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>table</th>\n",
       "      <th>field</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>null</th>\n",
       "      <th>zero</th>\n",
       "      <th>negative</th>\n",
       "      <th>pk</th>\n",
       "      <th>fk</th>\n",
       "      <th>table_fk</th>\n",
       "      <th>format</th>\n",
       "      <th>format_regex</th>\n",
       "      <th>range</th>\n",
       "      <th>values</th>\n",
       "      <th>null_limit</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ses_seguros.csv</td>\n",
       "      <td>ses_seguros</td>\n",
       "      <td>coenti</td>\n",
       "      <td>number</td>\n",
       "      <td>integer</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ses_cias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ses_seguros.csv</td>\n",
       "      <td>ses_seguros</td>\n",
       "      <td>damesano</td>\n",
       "      <td>data</td>\n",
       "      <td>undefined</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YYYYMM</td>\n",
       "      <td>^(199[0-9]|20[0-4][0-9]|2050)(0[1-9]|1[0-2])$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ses_cias.csv</td>\n",
       "      <td>ses_cias</td>\n",
       "      <td>coenti</td>\n",
       "      <td>number</td>\n",
       "      <td>integer</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de 1111 a 99999</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ses_ramos.csv</td>\n",
       "      <td>ses_ramos</td>\n",
       "      <td>coramo</td>\n",
       "      <td>number</td>\n",
       "      <td>integer</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ses_ramos.csv</td>\n",
       "      <td>ses_ramos</td>\n",
       "      <td>banana</td>\n",
       "      <td>number</td>\n",
       "      <td>integer</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file        table     field    type    subtype null zero  \\\n",
       "0  ses_seguros.csv  ses_seguros    coenti  number    integer   no   no   \n",
       "1  ses_seguros.csv  ses_seguros  damesano    data  undefined   no   no   \n",
       "2     ses_cias.csv     ses_cias    coenti  number    integer   no   no   \n",
       "3    ses_ramos.csv    ses_ramos    coramo  number    integer   no   no   \n",
       "4    ses_ramos.csv    ses_ramos    banana  number    integer   no   no   \n",
       "\n",
       "  negative   pk   fk  table_fk  format  \\\n",
       "0       no  yes  yes  ses_cias     NaN   \n",
       "1       no  yes   no       NaN  YYYYMM   \n",
       "2       no  yes   no       NaN     NaN   \n",
       "3       no  yes   no       NaN     NaN   \n",
       "4       no  yes   no       NaN     NaN   \n",
       "\n",
       "                                    format_regex            range  values  \\\n",
       "0                                            NaN              NaN     NaN   \n",
       "1  ^(199[0-9]|20[0-4][0-9]|2050)(0[1-9]|1[0-2])$              NaN     NaN   \n",
       "2                                            NaN  de 1111 a 99999   123.0   \n",
       "3                                            NaN              NaN     NaN   \n",
       "4                                            NaN              NaN     NaN   \n",
       "\n",
       "   null_limit active  \n",
       "0         NaN    yes  \n",
       "1         NaN    yes  \n",
       "2         NaN    yes  \n",
       "3         NaN    yes  \n",
       "4         NaN    yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega as configura√ß√µes e inicia o log \n",
    "df_config = pd.DataFrame([{}])\n",
    "load_config(df_config)\n",
    "\n",
    "# inicia o log com o path parametrizado\n",
    "init_log(df_config.loc[0, \"log_path\"])\n",
    "\n",
    "# Carrega a lista de valida√ß√µes\n",
    "df_validations = pd.DataFrame([{}])\n",
    "load_validations(df_validations,df_config.loc[0, \"eda_config_path\"] )\n",
    "\n",
    "# Carrega a lista de campos a validar\n",
    "df_fields = pd.DataFrame([{}])\n",
    "load_fields(df_fields, df_config.loc[0, \"eda_config_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1406eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result: List[Dict[str, Any]] = []\n",
    "# rotina pra salvar os resutlados das analises \n",
    "def save_result(\n",
    "    file: str, field: str, category: str, test: str, evidence: Any, detail: Optional[str] = None, status: str = \"PASS\") -> result:    \n",
    "    registry: result = { \"file\": file, \"Field\": field, \"category\": category, \"test\": test, \"evidence\": evidence, \"detail\": detail, \"status\": status,}\n",
    "    return registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdb464",
   "metadata": {},
   "source": [
    "Inicializa variaveis para leitura dos campos configurados para analise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c24e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame([{}])\n",
    "FAIL_TABLES = set()   # Controla falhas estruturais (Passo 1)\n",
    "loaded_file = \"\"\n",
    "separator = df_config.loc[0, \"separator\"]\n",
    "encode = df_config.loc[0, \"encode\"]\n",
    "new_file = True \n",
    "RESULTS = [] \n",
    "\n",
    "# Converte todos os campos para str\n",
    "df_fields = df_fields.astype('string')\n",
    "\n",
    "# Deixa todos os nomes de campos em minusculo e remove espa√ßos\n",
    "df_fields.columns = df_fields.columns.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7949e21",
   "metadata": {},
   "source": [
    "Inicio do Loop no campo a serem analisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527c0794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "ses_seguros\n",
      "------------------------------\n",
      "\n",
      "***********  coenti  **************\n",
      "---- Caracteristicas ----\n",
      "number\n",
      "integer\n",
      "no-null\n",
      "pk\n",
      "fk\n",
      "no-zero\n",
      "no-negative\n",
      "----- Analises aplicadas ----\n",
      "Teste: Null or empty values - Apply: no-null\n",
      "Teste: Zeros values - Apply: no-zero\n",
      "-------- Debug ----------\n",
      "2100\n",
      "100\n",
      "0\n",
      "-------- Debug ----------\n",
      "-------- Debug df_valores_numericos----------\n",
      "coenti\n",
      "int64\n",
      "-------- Debug ----------\n",
      "-------- Debug series_alvo ----------\n",
      "int64\n",
      "-------- Debug ----------\n",
      "Teste: Negative values - Apply: no-negative\n",
      "\n",
      "***********  damesano  **************\n",
      "---- Caracteristicas ----\n",
      "data\n",
      "no-null\n",
      "pk\n",
      "no-zero\n",
      "no-negative\n",
      "format\n",
      "----- Analises aplicadas ----\n",
      "Teste: Null or empty values - Apply: no-null\n",
      "Teste: Expected format (regex) - Apply: format\n",
      "Teste: Zeros values - Apply: no-zero\n",
      "-------- Debug ----------\n",
      "2100\n",
      "100\n",
      "0\n",
      "-------- Debug ----------\n",
      "-------- Debug df_valores_numericos----------\n",
      "damesano\n",
      "int64\n",
      "-------- Debug ----------\n",
      "-------- Debug series_alvo ----------\n",
      "int64\n",
      "-------- Debug ----------\n",
      "Teste: Negative values - Apply: no-negative\n",
      "------------------------------\n",
      "ses_cias\n",
      "------------------------------\n",
      "\n",
      "***********  coenti  **************\n",
      "---- Caracteristicas ----\n",
      "number\n",
      "integer\n",
      "no-null\n",
      "pk\n",
      "no-zero\n",
      "no-negative\n",
      "range\n",
      "values\n",
      "----- Analises aplicadas ----\n",
      "Teste: Null or empty values - Apply: no-null\n",
      "Teste: Zeros values - Apply: no-zero\n",
      "-------- Debug ----------\n",
      "3720\n",
      "743\n",
      "1\n",
      "-------- Debug ----------\n",
      "-------- Debug df_valores_numericos----------\n",
      "coenti\n",
      "int64\n",
      "-------- Debug ----------\n",
      "-------- Debug series_alvo ----------\n",
      "int64\n",
      "-------- Debug ----------\n",
      "Teste: Negative values - Apply: no-negative\n",
      "Teste: Valid ranges - Apply: range\n",
      "----------- DEBUG RANGE -----------\n",
      "1111.0\n",
      "99999.0\n",
      "----------- DEBUG RANGE -----------\n",
      "----------- DEBUG RANGE primeiro_range_invalido_indice -----------\n",
      "40\n",
      "----------- DEBUG RANGE primeiro_range_invalido_indice -----------\n",
      "------------------------------\n",
      "ses_ramos\n",
      "------------------------------\n",
      "\n",
      "***********  coramo  **************\n",
      "---- Caracteristicas ----\n",
      "number\n",
      "integer\n",
      "no-null\n",
      "pk\n",
      "no-zero\n",
      "no-negative\n",
      "----- Analises aplicadas ----\n",
      "Teste: Null or empty values - Apply: no-null\n",
      "Teste: Zeros values - Apply: no-zero\n",
      "-------- Debug ----------\n",
      "322\n",
      "161\n",
      "0\n",
      "-------- Debug ----------\n",
      "-------- Debug df_valores_numericos----------\n",
      "coramo\n",
      "int64\n",
      "-------- Debug ----------\n",
      "-------- Debug series_alvo ----------\n",
      "int64\n",
      "-------- Debug ----------\n",
      "Teste: Negative values - Apply: no-negative\n",
      "\n",
      "***********  banana  **************\n",
      "---- Caracteristicas ----\n",
      "number\n",
      "integer\n",
      "no-null\n",
      "pk\n",
      "no-zero\n",
      "no-negative\n",
      "----- Analises aplicadas ----\n",
      "Teste: Null or empty values - Apply: no-null\n",
      "Teste: Zeros values - Apply: no-zero\n",
      "Teste: Negative values - Apply: no-negative\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_fields.iterrows():\n",
    "\n",
    "    file_name = row[\"file\"]\n",
    "    table_name = row[\"table\"]\n",
    "    file_path = df_config.loc[0, \"data_path\"] + file_name\n",
    "\n",
    "    # Verifica se o arquivo est√° carregado ou j√° falhou\n",
    "    if (file_name in FAIL_TABLES): \n",
    "        continue \n",
    "    \n",
    "    if (row[\"file\"] != loaded_file):       \n",
    "        try: \n",
    "            try: # Carregamento do arquivo de dados\n",
    "\n",
    "                # Detecta o encode, se n√£o foi fornecido\n",
    "                try:\n",
    "                    if len(encode) == 0: \n",
    "                        detectado = from_path(str(file_path)).best() \n",
    "                        encoding_detectado = detectado.encoding \n",
    "                    else: \n",
    "                        encoding_detectado = encode\n",
    "                except Exception:\n",
    "                    encoding_detectado = 'utf-8' \n",
    "\n",
    "                # data Load    \n",
    "                df_data = pd.read_csv(file_path,encoding=encoding_detectado,sep=separator,engine='python')\n",
    "\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Falha no carregamento do arquivo !\")\n",
    "\n",
    "            loaded_file = file_name\n",
    "            new_file = True  \n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"‚ùå Erro de Codifica√ß√£o: O arquivo pode n√£o ser '{encoding}'. Tente outro encoding.\")\n",
    "        \n",
    "        except pd.errors.ParserError as e:\n",
    "            # Este erro geralmente indica problemas de estrutura (delimitadores incorretos, linhas mal formadas)\n",
    "            print(f\"‚ùå Erro de Parsing (Estrutura CSV incorreta): {e}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Captura outros erros, como FileNotFoundError\n",
    "            print(f\"‚ùå Erro inesperado ao ler o arquivo: {e}\") \n",
    "\n",
    "    if new_file: \n",
    "        print(\"-\" * 30 )\n",
    "        print(table_name)\n",
    "        print(\"-\" * 30 )\n",
    "        # Corrige o tipo das colunas \"int\" exibidas como \"float\" \n",
    "        for col in df_data.select_dtypes(include=[\"float\"]).columns:\n",
    "            if (df_data[col].dropna() % 1 == 0).all():\n",
    "                df_data[col] = df_data[col].astype(\"Int64\")        \n",
    "\n",
    "        # Coleta estatisticas no nivel do arquivo \n",
    "        file_size = format_file_size(os.path.getsize(file_path) )\n",
    "        line_count = len(df_data)\n",
    "        col_count = len(df_data.columns) \n",
    "        evidence_str = \"Tamanho: \" + file_size + \" Linhas/Colunas: \" + str(line_count) + \"/\" + str(col_count)\n",
    "        RESULTS.append(save_result(row[\"file\"],  \"Todos\",\"structure\",\"file info\",evidence_str,\"\", \"pass\")) \n",
    "\n",
    "        # Sanitiza√ß√£o da taberla de dados \n",
    "        # Deixa todos os nomes de campos em minusculo e remove espa√ßos\n",
    "        df_data.columns = df_data.columns.str.strip().str.lower()   \n",
    "        # print(df_data.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "        # Testa colunas faltantes\n",
    "        missing_columns_lst = [] \n",
    "        df_expected_columns = (df_fields[df_fields['table'] == table_name]['field'].unique()) \n",
    "        data_column_names = df_data.columns.to_list()\n",
    "        df_data_columns = pd.DataFrame({\"column\": data_column_names})\n",
    "        expected_set = set([c.strip().lower() for c in df_expected_columns])\n",
    "        data_set = set(df_data_columns['column'].str.strip().str.lower().tolist())\n",
    "        missing_colunms = expected_set.difference(data_set)\n",
    "        missing_columns_lst = list(missing_colunms)\n",
    "        if missing_colunms:\n",
    "            str_missing_columns = \", \".join(sorted(list(missing_colunms)))\n",
    "        else:\n",
    "            str_missing_columns = \"nenhuma\"\n",
    "        \n",
    "        # Testa colunas com nome duplicados\n",
    "        nomes_colunas = [col.strip().lower() for col in df_data.columns.tolist()]\n",
    "        nomes_series = pd.Series(nomes_colunas)\n",
    "        nomes_sem_sufixo = nomes_series.str.replace(r'\\.\\d+$', '', regex=True)\n",
    "        contagem_nomes = nomes_sem_sufixo.value_counts()\n",
    "        nomes_duplicados_series = contagem_nomes[contagem_nomes > 1]\n",
    "        lista_nomes_duplicados = nomes_duplicados_series.index.tolist()\n",
    "        colunas_duplicadas = df_data_columns['column'].value_counts()\n",
    "        if lista_nomes_duplicados:\n",
    "            # Junta os nomes duplicados com \", \"\n",
    "            resultado_string = \", \".join(lista_nomes_duplicados)\n",
    "        else:\n",
    "            resultado_string = \"nenhum\"\n",
    "        if resultado_string == \"nenhum\" and str_missing_columns == \"nenhuma\": \n",
    "            status = \"pass\" \n",
    "        else: \n",
    "            status = \"fail\"\n",
    "\n",
    "        evidence_str =  \"Faltantes: \" +  str_missing_columns + \" Nomes_duplicados: \" + resultado_string          \n",
    "        RESULTS.append(save_result(row[\"file\"], \"Todos\" ,\"structure\",\"Column info\",evidence_str,\"\", status)) \n",
    "            \n",
    "        new_file = False\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"***********  \" + row[\"field\"] + \"  **************\")\n",
    "\n",
    "    # Monta a lista de caracteristicas do campo para chamada dos checagens corresposndentes \n",
    "    apply_list = field_apply_list(df_data, df_fields, row)\n",
    "    print(\"---- Caracteristicas ----\")\n",
    "    for item in  apply_list: \n",
    "        print(item) \n",
    "\n",
    "    # Busca as checagens Ativas correspondentes as caracteristicas do campo  \n",
    "    apply_set = set([item.strip().lower() for item in apply_list]) \n",
    "    mask_apply = df_validations['apply'].apply(lambda x: len(set(str(x).lower().replace(' ', '').split(',')) & apply_set) > 0)\n",
    "    mask_active = (df_validations['active'] == 'yes')\n",
    "    df_filtrado = df_validations[mask_apply&mask_active]\n",
    "\n",
    "    # Loop de chamada das analises \n",
    "    print(\"----- Analises aplicadas ----\")\n",
    "    for index, check_row in df_filtrado.iterrows():\n",
    "        try: \n",
    "            print(\"Teste: \" + check_row[\"test\"]+ \" - Apply: \" + check_row[\"apply\"] ) \n",
    "            if str(row[\"field\"]) in list(missing_columns_lst): # ignora colunas que n√£o foram encontrados\n",
    "                continue  \n",
    "            #  chama a rotina parametrizada para a analise\n",
    "            evidence, status, detail  = getattr(src.analisys,check_row[\"routine\"])(df_data, df_fields, row)  \n",
    "            # Salva o resultado das analise no relat√µrio final\n",
    "            RESULTS.append(save_result(row[\"file\"], row[\"field\"] ,check_row[\"category\"],check_row[\"test\"],evidence,detail, status)) \n",
    "        except Exception as e:\n",
    "            evidence = \"Falha na chamada da rotina de analise\"\n",
    "            status = \"error\"\n",
    "            detail = (f\"Rotina '{check_row[\"routine\"]}': \" f\"{type(e).__name__}: {str(e)}\")\n",
    "            RESULTS.append(save_result(row[\"file\"], row[\"field\"] ,check_row[\"category\"],check_row[\"test\"],evidence,detail, status)) \n",
    "\n",
    "            continue\n",
    "\n",
    "    # Chama as rotinas basicas (qualquer tipo de campo)\n",
    "    # df_basic_checks = df_validations[(df_validations['category'] == 'basic') & (df_validations['active'] == 'yes')]\n",
    "    # print(\"df_basic_checks\")\n",
    "    # print(df_basic_checks)\n",
    "    # for index, check_row in df_basic_checks.iterrows():\n",
    "    #     evidence, status, detail  = getattr(src.analisys,check_row[\"routine\"])(df_data, df_fields, row)\n",
    "    #     print(\"Retorno\")\n",
    "    #     print(evidence, status, detail)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb1819",
   "metadata": {},
   "source": [
    "Fim do loop de analise e de campos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4867c24",
   "metadata": {},
   "source": [
    "Gera o relat√µrio de saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f05649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        --- üìã REGISTROS DE AUDITORIA ---                        \n",
      "================================================================================\n",
      "   status file             Field     test                     evidence                                     detail                                                         \n",
      "0   pass   ses_seguros.csv     Todos                file info      Tamanho: 7.56 KB Linhas/Colunas: 100/21                                                                \n",
      "1   pass   ses_seguros.csv     Todos              Column info  Faltantes: nenhuma Nomes_duplicados: nenhum                                                                \n",
      "2   pass   ses_seguros.csv    coenti     Null or empty values                                 0 aus√™ncias.               Nenhum valor nulo ou vazio detectado neste campo.\n",
      "3   fail   ses_seguros.csv    coenti             Zeros values                               Zerados: 1.00%            Linha com exemplo de erro: (70): Valor encontrado: 0\n",
      "4   fail   ses_seguros.csv    coenti          Negative values                             Negativos: 1.00%        Linha com exemplo de erro: (80): Valor encontrado: -5096\n",
      "5   pass   ses_seguros.csv  damesano     Null or empty values                                 0 aus√™ncias.               Nenhum valor nulo ou vazio detectado neste campo.\n",
      "6   fail   ses_seguros.csv  damesano  Expected format (regex)                      Compatibilidade: 99.00%                            Exemplo de erro: '110001' (linha 51)\n",
      "7   pass   ses_seguros.csv  damesano             Zeros values                               Zerados: 0.00%                                                                \n",
      "8   pass   ses_seguros.csv  damesano          Negative values                             Negativos: 0.00%                                                                \n",
      "9   pass      ses_cias.csv     Todos                file info      Tamanho: 59.56 KB Linhas/Colunas: 744/5                                                                \n",
      "10  fail      ses_cias.csv     Todos              Column info  Faltantes: nenhuma Nomes_duplicados: noenti                                                                \n",
      "11  fail      ses_cias.csv    coenti     Null or empty values                          1 aus√™ncias (0.13%)  Total de 1 ausente(s) (0.13%) [Nulos: 0, Vazios/Whitespace: 1]\n",
      "12  pass      ses_cias.csv    coenti             Zeros values                               Zerados: 0.00%                                                                \n",
      "13  pass      ses_cias.csv    coenti          Negative values                             Negativos: 0.00%                                                                \n",
      "14  fail      ses_cias.csv    coenti             Valid ranges                         fora do range: 0.81%          Linha com exemplo de erro: (38): Valor encontrado: 444\n",
      "15  pass     ses_ramos.csv     Todos                file info       Tamanho: 6.96 KB Linhas/Colunas: 161/2                                                                \n",
      "16  fail     ses_ramos.csv     Todos              Column info   Faltantes: banana Nomes_duplicados: nenhum                                                                \n",
      "17  pass     ses_ramos.csv    coramo     Null or empty values                                 0 aus√™ncias.               Nenhum valor nulo ou vazio detectado neste campo.\n",
      "18  pass     ses_ramos.csv    coramo             Zeros values                               Zerados: 0.00%                                                                \n",
      "19  pass     ses_ramos.csv    coramo          Negative values                             Negativos: 0.00%                                                                \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Exibe os registros de auditoria em um formato tabular otimizado\n",
    "    para visualiza√ß√£o em tela, sem quebras de linha em um mesmo registro.\n",
    "    \"\"\"\n",
    "# 1. Manter a configura√ß√£o do cabe√ßalho √† esquerda (que voc√™ j√° fez)\n",
    "pd.set_option('display.colheader_justify', 'left') \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# 2. Definir a ordem das colunas\n",
    "colunas_exibicao = ['status', 'file', 'Field', 'test', 'evidence', 'detail']\n",
    "\n",
    "if RESULTS:\n",
    "    DF_RESULTS = pd.DataFrame(RESULTS)\n",
    "\n",
    "    # --- A CORRE√á√ÉO CR√çTICA ---\n",
    "    # Usar justify='left' no m√©todo to_string() for√ßa TODO o conte√∫do\n",
    "    # (incluindo n√∫meros) a ser alinhado √† esquerda.\n",
    "    tabela_formatada = DF_RESULTS[colunas_exibicao].to_string(justify='left')\n",
    "    \n",
    "    # 3. Imprimir\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"--- üìã REGISTROS DE AUDITORIA ---\".center(80))\n",
    "    print(\"=\"*80)\n",
    "    print(tabela_formatada)\n",
    "    \n",
    "    # 4. Reverter as op√ß√µes (boa pr√°tica)\n",
    "    pd.reset_option('display.colheader_justify')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "\n",
    "else:\n",
    "    print(\"A lista 'RESULTS' est√° vazia.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-o-matic-HKdgnQC0-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
